{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a22013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution: Counter({1: 2625, 0: 1993})\n",
      "\n",
      "Naive_Bayes | bow\n",
      "Accuracy : 0.9686\n",
      "F1 Score : 0.9730\n",
      "----------------------------------------\n",
      "\n",
      "Logistic_Regression | bow\n",
      "Accuracy : 0.9502\n",
      "F1 Score : 0.9569\n",
      "----------------------------------------\n",
      "\n",
      "Linear_SVM | bow\n",
      "Accuracy : 0.9286\n",
      "F1 Score : 0.9368\n",
      "----------------------------------------\n",
      "\n",
      "Naive_Bayes | tfidf\n",
      "Accuracy : 0.9502\n",
      "F1 Score : 0.9578\n",
      "----------------------------------------\n",
      "\n",
      "Logistic_Regression | tfidf\n",
      "Accuracy : 0.9470\n",
      "F1 Score : 0.9551\n",
      "----------------------------------------\n",
      "\n",
      "Linear_SVM | tfidf\n",
      "Accuracy : 0.9632\n",
      "F1 Score : 0.9682\n",
      "----------------------------------------\n",
      "\n",
      "Naive_Bayes | tfidf_bigram\n",
      "Accuracy : 0.9221\n",
      "F1 Score : 0.9355\n",
      "----------------------------------------\n",
      "\n",
      "Logistic_Regression | tfidf_bigram\n",
      "Accuracy : 0.9416\n",
      "F1 Score : 0.9507\n",
      "----------------------------------------\n",
      "\n",
      "Linear_SVM | tfidf_bigram\n",
      "Accuracy : 0.9610\n",
      "F1 Score : 0.9664\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    # Selecting only sport and politics related categories (out of the 20 topics od data present in the dataset)\n",
    "    categories = [\n",
    "        'rec.sport.baseball',\n",
    "        'rec.sport.hockey',\n",
    "        'talk.politics.misc',\n",
    "        'talk.politics.guns',\n",
    "        'talk.politics.mideast'\n",
    "    ]\n",
    "\n",
    "    # Fetch desired dataset (The 20 newsgroups text dataset)\n",
    "    dataset = fetch_20newsgroups(\n",
    "        subset='all',\n",
    "        categories=categories,\n",
    "        remove=('headers', 'footers', 'quotes')\n",
    "    )\n",
    "\n",
    "    X = dataset.data\n",
    "    y = dataset.target\n",
    "\n",
    "    # In this filtered dataset:\n",
    "    # Index 0,1 correspond to sports\n",
    "    # Remaining correspond to politics\n",
    "    sport_indices = [0, 1]\n",
    "\n",
    "    # COnverting to binary labels\n",
    "    y_binary = np.array([0 if label in sport_indices else 1 for label in y])\n",
    "\n",
    "    print(\"Class Distribution:\", Counter(y_binary))\n",
    "    return X, y_binary\n",
    "\n",
    "\n",
    "def get_features(X_train, X_test, feature_type):\n",
    "\n",
    "    if feature_type == \"bow\":\n",
    "        # Bag of Words representation\n",
    "        vectorizer = CountVectorizer(stop_words='english')\n",
    "    elif feature_type == \"tfidf\":\n",
    "        # TF-IDF representation\n",
    "        vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    elif feature_type == \"tfidf_bigram\":\n",
    "        # TF-IDF with unigrams + bigrams\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid feature type\")\n",
    "    \n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    return X_train_vec, X_test_vec\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, model_name, feature_type):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm)\n",
    "    plt.title(f\"{model_name} - {feature_type}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "\n",
    "    # Binary class labels\n",
    "    plt.xticks([0, 1], [\"Sport\", \"Politics\"])\n",
    "    plt.yticks([0, 1], [\"Sport\", \"Politics\"])\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, cm[i, j], ha='center')\n",
    "\n",
    "    plt.colorbar()\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    plt.savefig(f\"results/{model_name}_{feature_type}_cm.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess dataset\n",
    "    # X -> Text documents\n",
    "    # y -> Binary Label (0: Sports & 1: Politics)\n",
    "    X, y = load_data()\n",
    "\n",
    "    # Split into training and testing (80-20 split)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y       # to preserve class distribution in the split\n",
    "    )\n",
    "\n",
    "    feature_types = [\"bow\", \"tfidf\", \"tfidf_bigram\"]\n",
    "\n",
    "    models = {\n",
    "        \"Naive_Bayes\": MultinomialNB(),\n",
    "        \"Logistic_Regression\": LogisticRegression(max_iter=2000),\n",
    "        \"Linear_SVM\": LinearSVC()\n",
    "    }\n",
    "\n",
    "    for feature in feature_types:\n",
    "\n",
    "        # Convert text to numerical features\n",
    "        X_train_vec, X_test_vec = get_features(X_train, X_test, feature)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "\n",
    "            # Train model on train and Predict results on test\n",
    "            model.fit(X_train_vec, y_train)\n",
    "            y_pred = model.predict(X_test_vec)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            plot_confusion_matrix(cm, model_name, feature)\n",
    "\n",
    "            print(f\"\\n{model_name} | {feature}\")\n",
    "            print(f\"Accuracy : {acc:.4f}\")\n",
    "            print(f\"F1 Score : {f1:.4f}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead076e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
